\chapter{Conclusion}
\label{chap:conclusion}
\section{Thesis Summary}
Knowledge graphs capture information about the real world and play an important role in various information systems. However, due to the automatic construction, KGs are usually incomplete so that a large amount of research effort has been committed to address this problem.

Solutions for the KGs completion problem often fall into the two categories: \textit{embedding-based} approach and \textit{rule-based} approach. In this thesis, we have presented a hybrid approach for learning non-monotonic rules from KGs that dynamically exploits feedback from a precomputed embedding model. Our method is general in that any embedding model can be utilized including text-enhanced ones, which indirectly allows us to harness unstructured web sources for rule learning. We evaluated our approach with various configurations on real-world datasets and observed significant improvements over state-of-the-art rule learning systems.
\section{Future Research Directions}
Regarding our approach, several prominent research directions could be considered to further advance this work. In what follows, we discuss the most important ones.
\subsection{Incorporation of other embedding models}
Currently, we are supporting only 3 embedding models namely TransE, HolE and SSP. While TransE and HolE models work based only on the given KG, SSP model provides the integration of entity descriptions. However, a variety of other embedding models exist that can even support different types of external data such as temporal knowledge and general Web-texts. These embedding models are more advanced and might produce better predictions than the ones that we exploited. Hence, injecting better embedding models is a promising direction for further facilitation of practicability of our approach.

\subsection{Incorporation of multiple heterogeneous external sources}
In this work, we currently rely on only a single external source, which is an embedding model. However, other types of external sources could be likewise taken into account to improve the quality of our approach. Technically, our external quality function $\mu_2$ is computed based on facts predicted by a given rule. One idea regarding the extension of our rule learning method is to exploit different external sources depending on the rule head predicate to quantify the rule quality.
Here, several possibilities exist:

\noindent- First, since the performance of different embedding models varies for different predicates \cite{Bordes:NIPS2013}, we can use the embedding models to assess only selected relations on which they perform well.

\noindent- Second, by separating relations, we can even combine the unsupervised and supervised learning settings. For instance, besides using embedding models for the relations on which they do perform well, we can also involve human judgement for other relations that are problematic for embedding models. Note that, naturally when using human inspection, the probabilistic fact assessment function $f$ would return binary values $\{0,1\}$.

\noindent- Third, different external sources could be incorporated for learning rules from general KGs, which contain relations from various domains. In particular, when learning rules from a KG with different predicates, the external quality function $\mu_2$ could be computed per predicate independently by using models trained with different domain-specific external data. For example, for movie-related predicates, IMDB could be invoked, whereas for sport-related ones, we can use data from dedicated sport websites. However, the challenge here is to figure out how to integrate these external sources to extend our hybrid probabilistic function $f$.

Incorporating many external sources can certainly improve the quality of the learned rules. However, this likely comes with the price of the increased running time and possibly memory overload. So, finding the tradeoff between these two aspects is an important point for further research.

\subsection{Auto-tuning embedding weight value}
As our experiments demonstrate, the value of the embedding weight $\lambda$ is crucial for achieving good results with our approach. Within this thesis, the best value of $\lambda$ has been empirically determined for every considered embedding model. Manually choosing a suitable value of $\lambda$ for an arbitrary dataset and embedding model requires a lot of human efforts. Hence, a relevant extension of our work concerns the development of an automatic procedure for computing the optimal weight $\lambda$. Naive strategy here would be to automate the procedure executed in Experiment \ref{exp:1}. However, other advanced and less costly solutions should exist.

Additionally, following the idea of treating every rule predicate individually as mentioned before, one can even automatically learn different values of $\lambda$ per predicate.

\subsection{Incorporation of various classical rule measures}
In this thesis, we considered \textit{standard confidence}, \textit{PCA confidence} and \textit{conviction} as classical rule measures. However, there are more sophisticated rule measures $\mu_1$ that could be also studied empirically, e.g., \textit{soft confidence} \cite{rdf2rules}, \textit{completeness-aware} measures \cite{carl}, \textit{RC confidence} \cite{measureskg}, etc. However, the challenge here is to choose the metric which is the most suitable for the dataset. For instance, \textit{PCA confidence} only performs well if the KG follows the Partial Closed-world Assumption, \textit{soft confidence} requires $type$ information to be available in the KG, and \textit{completeness-aware} measures ask for extra (in-)completeness meta-data about the KG in form of cardinality statements.

\subsection{Iterative improvement of rules and embedding model}
As mentioned in Section \ref{related_work:combine}, a variety of approaches introducing embedding models that make use of prespecified rules have been provided in the literature. So, if we plug these embedding models in our approach, an iterative improvement of rules and embedding models could be developed as sketched follows. We start with some rules extracted from a rule mining system (e.g., our system with $\lambda = 0$). Then, these initial rules are used to train the embedding model. Repeatedly, rules are then revised using our approach and rely on the trained model, which results in an iterative procedure.

\subsection{Inference of facts from intersection of rules and external source}
Currently, the main output of our approach is rules. In highly incomplete KGs, the precision of rules is normally rather low, which leads to the incorrectness of inferred facts. To tackle this issue, one could learn more complex rules (e.g., with more atoms), which could improve the likelihood of predicted facts by pruning low quality branches. However, overcoming the barrier of language bias is not easy in this context.

An alternative solution is to infer facts based on the intersection of predictions between the rules and the external source. For example, we could predict a fact as being true only if the external source gives it a probability value $f$ above a pre-defined threshold, and at the same time, the fact is binded with some rule that is confident enough. The main drawback of this method is that, while precision of predicted facts obviously increases, their recall could decrease significantly. Hence, computing the optimal thresholds is the main challenge of this research direction, which is quite interesting to study.

% \section{Conclusions}

% Advances in Information Extraction have led to the construction of large KGs in the form of \textit{$\langle$subject predicate object$\rangle$} triples. However, due to the automatic construction, these KGs can be incomplete. Horn rule mining is a popular approach to address this issue~\cite{ref10}.

% In this thesis we have looked at the problem of enhancing the quality of positive rules and subsequently improving the accuracy of their predictions, by revising the mined rules into the nonmonotonic ones. We follow the ideas from~\cite{ref12} where the same problem was studied for KGs containing only unary facts. Meanwhile, RUMIS tool implemented in our research generates nonmonotonic rules from KGs in their original format.

% We have extended the results from~\cite{ref12} to KG revision in their original relational form and developed the RUMIS system, for learning nonmonotonic rules in KGs under the OWA. Subsequently, the chosen revisions are exploited to extend the original data, and thus, they are suitable for tackling the KG completion problem. Some experiments in the thesis are conducted for testing quality of rules generated by RUMIS and the results demonstrate that the proposed approach outperforms the state of the art KG rule learning systems w.r.t. to the quality of the made predictions.

% \section{Future Directions}

% We now discuss possible future directions.

% \begin{itemize}
% \item \textbf{Tackle language bias challenge.} In this work we have fixed the language bias of the rules to be mined. Certainly, a promising and natural direction is to extend our results to further rule forms and make the language bias more flexible. The language bias can be manually specified by users, which should make the RUMIS system less restrictive and diversify possible revisions. Another possible future direction is to consider existential operators in the heads of the positive rules, e.g., \textit{$\exists$ Y hasParent(X, Y) $\leftarrow$ person(X)}.
% \item \textbf{Enriching exception forms.} Currently RUMIS only supports one exception in the body and this exception is the relation between variables in the head or a unary atom. To extend the form of nonmonotonic rules, we can increase the number of exceptions in the body of the revision. E.g., an interesting rule like \textit{isCitizenOf(X, Y) $\leftarrow$ bornIn(X, Y), not manager(X), not isAsiaCountry(Y)} could then be mined.
% \item \textbf{Optimizations.} Due to the large size of the KGs, data indexing is a time burden step in our implementation. Thus, a natural optimization direction is to store the facts in a database and to build a web service for finding results of conjunctive relational queries. Thanks to this technique, we will only build the service once at the beginning, and the data indexing step will not be necessary for every execution of the RUMIS system. Hence, the total time of the experiment should be significantly reduced.
% \item \textbf{Try more rule measures.} Other predictive measures and exception evaluation methods can be tested to search for interesting nonmonotonic rules. A survey in~\cite{ref46} specifies a variety of choices for predictive rule measures, where conviction is only one of them.
% \item \textbf{N-ary facts.} In YAGO and IMDB datasets, the facts are three-dimensional, i.e., each of them contains a subject, a predicate and an object. The Wikidata Football dataset exploited in the experiments has the same property, i.e., it is extracted from simplified version of original Wikidata where all facts are projected to three-dimensional space. One possible future extension would be to take the n-ary facts, i.e., facts containing n-parameters, into consideration. E.g., the five-dimensional fact \textit{$<$Ronaldo$>$ $<$playsFor$>$ $<$Manchester United$>$ $<$in$>$ $<$2008$>$} may appear in the full Wikidata KG.
% \item \textbf{Training KG random sampling.} In our current experiment, every learning KG is chosen from the ideal KG by removing 20\% of facts for each binary predicate. This setting is a bit restrictive, because it tries to maintain the distribution of facts over the predicates. It is worth testing the quality of predictions generated by RUMIS if the training data is chosen randomly by varying the percentage of the retained facts for every relation.
% \item \textbf{Optimize DLV.} DLV running time is a burden in the current system. Indeed, for very large KGs and 10 revised rules, it takes up to days to produce predictions. Since completing a given KG is one of the main goals of the tool, optimizations of the DLV tool should be studied to make sure that the total run time performance is acceptable.
% \item \textbf{Facts with probability.} For our experiment, the facts in the given KG are always true, which is not always the case, where some facts might be totally wrong. Indeed, modern KGs might contain incorrect triples, since their large parts are constructed automatically by information extraction techniques. As a possible future direction, probability can be assigned to facts in the training KG as the weight, and taken into account during the rule learning and revision. This will result in new predictions with confidence weights assigned to them.
% \end{itemize}